{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb728bf-f1b5-46e2-9a0f-a24a04341647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3418973-2dcc-47ff-9533-8e8e1a4b930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñêÔ∏è Real-Time Hand Landmark Capture\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the label for this gesture (e.g., A, B, Hello):  Space\n",
      "How many samples to capture? (default 30):  103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting 103 samples for label: Space\n",
      "Press 's' to start capturing, 'q' to quit\n",
      "Starting capture...\n",
      "Captured sample 1/103\n",
      "Captured sample 2/103\n",
      "Captured sample 3/103\n",
      "Captured sample 4/103\n",
      "Captured sample 5/103\n",
      "Captured sample 6/103\n",
      "Captured sample 7/103\n",
      "Captured sample 8/103\n",
      "Captured sample 9/103\n",
      "Captured sample 10/103\n",
      "Captured sample 11/103\n",
      "Captured sample 12/103\n",
      "Captured sample 13/103\n",
      "Captured sample 14/103\n",
      "Captured sample 15/103\n",
      "Captured sample 16/103\n",
      "Captured sample 17/103\n",
      "Captured sample 18/103\n",
      "Captured sample 19/103\n",
      "Captured sample 20/103\n",
      "Captured sample 21/103\n",
      "Captured sample 22/103\n",
      "Captured sample 23/103\n",
      "Captured sample 24/103\n",
      "Captured sample 25/103\n",
      "Captured sample 26/103\n",
      "Captured sample 27/103\n",
      "Captured sample 28/103\n",
      "Captured sample 29/103\n",
      "Captured sample 30/103\n",
      "Captured sample 31/103\n",
      "Captured sample 32/103\n",
      "Captured sample 33/103\n",
      "Captured sample 34/103\n",
      "Captured sample 35/103\n",
      "Captured sample 36/103\n",
      "Captured sample 37/103\n",
      "Captured sample 38/103\n",
      "Captured sample 39/103\n",
      "Captured sample 40/103\n",
      "Captured sample 41/103\n",
      "Captured sample 42/103\n",
      "Captured sample 43/103\n",
      "Captured sample 44/103\n",
      "Captured sample 45/103\n",
      "Captured sample 46/103\n",
      "Captured sample 47/103\n",
      "Captured sample 48/103\n",
      "Captured sample 49/103\n",
      "Captured sample 50/103\n",
      "Captured sample 51/103\n",
      "Captured sample 52/103\n",
      "Captured sample 53/103\n",
      "Captured sample 54/103\n",
      "Captured sample 55/103\n",
      "Captured sample 56/103\n",
      "Captured sample 57/103\n",
      "Captured sample 58/103\n",
      "Captured sample 59/103\n",
      "Captured sample 60/103\n",
      "Captured sample 61/103\n",
      "Captured sample 62/103\n",
      "Captured sample 63/103\n",
      "Captured sample 64/103\n",
      "Captured sample 65/103\n",
      "Captured sample 66/103\n",
      "Captured sample 67/103\n",
      "Captured sample 68/103\n",
      "Captured sample 69/103\n",
      "Captured sample 70/103\n",
      "Captured sample 71/103\n",
      "Captured sample 72/103\n",
      "Captured sample 73/103\n",
      "Captured sample 74/103\n",
      "Captured sample 75/103\n",
      "Captured sample 76/103\n",
      "Captured sample 77/103\n",
      "Captured sample 78/103\n",
      "Captured sample 79/103\n",
      "Captured sample 80/103\n",
      "Captured sample 81/103\n",
      "Captured sample 82/103\n",
      "Captured sample 83/103\n",
      "Captured sample 84/103\n",
      "Captured sample 85/103\n",
      "Captured sample 86/103\n",
      "Captured sample 87/103\n",
      "Captured sample 88/103\n",
      "Captured sample 89/103\n",
      "Captured sample 90/103\n",
      "Captured sample 91/103\n",
      "Captured sample 92/103\n",
      "Captured sample 93/103\n",
      "Captured sample 94/103\n",
      "Captured sample 95/103\n",
      "Captured sample 96/103\n",
      "Captured sample 97/103\n",
      "Captured sample 98/103\n",
      "Captured sample 99/103\n",
      "Captured sample 100/103\n",
      "Captured sample 101/103\n",
      "Captured sample 102/103\n",
      "Captured sample 103/103\n",
      "\n",
      "‚úÖ Successfully saved 103 samples to collected_data/Space.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,  # Change to 2 if you want both hands\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize CSV file\n",
    "def init_csv():\n",
    "    columns = ['label']\n",
    "    for i in range(21):  # 21 landmarks per hand\n",
    "        columns.extend([f'x{i}', f'y{i}', f'z{i}'])\n",
    "    return columns\n",
    "\n",
    "# Capture hand landmarks from webcam\n",
    "def capture_landmarks(label, num_samples=30, delay=1000):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    csv_columns = init_csv()\n",
    "    data = []\n",
    "    sample_count = 0\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs('collected_data', exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    csv_filename = f\"collected_data/{label}.csv\"\n",
    "    \n",
    "    print(f\"\\nCollecting {num_samples} samples for label: {label}\")\n",
    "    print(\"Press 's' to start capturing, 'q' to quit\")\n",
    "    \n",
    "    capturing = False\n",
    "    last_capture_time = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Flip frame horizontally for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Convert to RGB and process with MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_frame)\n",
    "        \n",
    "        # Draw landmarks if detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                # Capture landmarks when in capturing mode\n",
    "                if capturing and sample_count < num_samples:\n",
    "                    current_time = cv2.getTickCount()\n",
    "                    if (current_time - last_capture_time) / cv2.getTickFrequency() * 1000 > delay:\n",
    "                        landmarks = []\n",
    "                        for lm in hand_landmarks.landmark:\n",
    "                            landmarks.extend([lm.x, lm.y, lm.z])\n",
    "                        \n",
    "                        data.append([label] + landmarks)\n",
    "                        sample_count += 1\n",
    "                        last_capture_time = current_time\n",
    "                        print(f\"Captured sample {sample_count}/{num_samples}\")\n",
    "        \n",
    "        # Display instructions\n",
    "        status_text = f\"Captured: {sample_count}/{num_samples}\" if capturing else \"Press 's' to start\"\n",
    "        cv2.putText(frame, status_text, (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Label: {label}\", (10, 70), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Press 'q' to quit\", (10, 110), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Hand Landmark Capture', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('s'):\n",
    "            capturing = True\n",
    "            print(\"Starting capture...\")\n",
    "        elif key == ord('q') or sample_count >= num_samples:\n",
    "            break\n",
    "    \n",
    "    # Save collected data\n",
    "    if data:\n",
    "        df = pd.DataFrame(data, columns=csv_columns)\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"\\n‚úÖ Successfully saved {len(data)} samples to {csv_filename}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No data collected\")\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üñêÔ∏è Real-Time Hand Landmark Capture\")\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    label = input(\"Enter the label for this gesture (e.g., A, B, Hello): \").strip()\n",
    "    num_samples = int(input(\"How many samples to capture? (default 30): \") or 30)\n",
    "    \n",
    "    capture_landmarks(label, num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850df428-fd60-4d98-a909-39e6494e6eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
